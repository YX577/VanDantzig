+ 137.194 * S^0.5 + 1.62247 * S)
+ (-24.4344 - 25.085 * S^0.5 - 0.2474 * S) * log(T)  # 'log' is fuction for natural log in R
+ (0.053105 * S^0.5 * T))                            # log10 is function for base 10 log
rm(list = ls())
graphics.off()
T = 298.15 #K       # Variables can be assigned values using "=" or "<-" (arrow sign)
S <- 35 #psu
K_B = exp((-8966.9 - 2890.51 * S^0.5 - 77.942 * S
+ 1.726 * S^1.5 - 0.0993 * S^2)/T + (148.0248
+ 137.194 * S^0.5 + 1.62247 * S)
+ (-24.4344 - 25.085 * S^0.5 - 0.2474 * S) * log(T)  # 'log' is fuction for natural log in R
+ (0.053105 * S^0.5 * T))                            # log10 is function for base 10 log
pK_B = -log10(K_B)                        # (pH at which both species is at 50% equilibrium)
pH = seq(4, 12, by = 0.5)                 # Set vector (sequence) of pH values from 4 - 12 in increments of 0.5
pH_K = 10^-pH                             # set vector of Hydrogen activity, aH+, to achieve pH
ratio = K_B / pH_K                        # Ratio of Borate to Boric Acid (products to reactants)
Borate = (ratio / (ratio + 1)) * 100      # Percent of total solution of Borate ion
Boric_Acid =  100 - Borate                # Percent of total solution of Boric Acid (subtract from 100 to get inverse)
Proportion <- array(NA, dim = c(17,3))    # This creates a blank table with 3 columns and 17 rows, and initializes with
View(Proportion)
View(Proportion)
colnames(Proportion) <- c("pH", "% Boric Acid", "% Borate Ion")   # Sets the names of the columns in the table
View(Proportion)
Proportion[,1] <- pH              # You can isolate individual rows/columns of a matrix/table using the following notation:
Proportion[,2] <- Boric_Acid
Proportion[,3] <- Borate
View(Proportion)                  # Lets you view a variable in a new window
?lty
?col
plot(pH, Boric_Acid,                                # "plot" function begins the plot, with the x and y variable in that order
type = 'l',                                    # "type = 'l'" signifies a line plot
ylim = c(0,100),                               # "ylim" manually sets the min and max y-axis dimensions
lwd = 2,                                       # "lwd" = linewidth. Default is 1, increasing numbers get thicker
pch = 19,                                      # "pch" = point character? Google it (or type '?pch'), there are multiple different point styles to choose
cex = 0.5,                                     # "cex" = character expansion (increases/decreases point size). Default = 1
ylab = "% of total DIC",                       # "ylab" = y-axis label
xlab = "pH")                                   # "xlab" = x-axis label
abline(v = pK_B, col = "gray")                      # "abline" sets straight lines. v=vertical, h=horizontal. You set the value of the y/x intercept
abline(h = 50, col = "gray")
points(pH, Borate, type = 'o',                      # "points" tells the plot to create scatterplot with x=pH, y=Borate. Type "o" is connected points
lty = 2,                                     # "lty" = linetype. Default is 1 (regular line), 2 is dashed
col = "blue",                                # "col" = color. R has multiple colors built in that can be called by name
pch = 19,
cex = 0.5,
lwd = 2)
legend(x="topleft",                                 # "legend" creates a legend. "Topleft" indicates location on plot
inset=c(0.05,0.1),                           # inset the legend into graph
legend=c("Boric Acid", "Borate Ion"),        # sets the name for the elements in the legend
col=c("black","blue"),
lty=c("solid","dashed"),                     # sets linetypes for legend. "solid" corresponds with "Boric Acid"
lwd=c(2,2,2)
)
box(lwd = 2)                                        # "box" just puts a box outline around the plot. Here I wanted to make the outline thicker
test <- seq(1,10, 1)
plot(rnorm(100))
plot(rnorm(100), col = "red")
plot(hist(rnorm(100)))
plot(hist(rnorm(100)))
plot(rnorm(100))
point(rnorm(1000), col = "green")
points(rnorm(1000), col = "green")
?rm.NA
a <- seq(1,20, 1)
b = function(x){
a^2 + 2*a + 2
}
b = function(a){
a^2 + 2*a + 2
}
b
b(a)
plot(a, b(a))
plot(b(a), b(a)/2*b(a))
test <- rnorm(100)
test[100:120] = NA
View(test)
test2 <- sample(test, 1000)
test2 <- sample(test, 1000, replace = T)
View(test2)
?sample
?if
?if
else
help(if)
test2 <- if test =/ NA, sample(test, 1000, replace = T)
?na.omit
test2 <- na.omit(test)
View(test2)
test <- rnorm(100)
test[101:120] = NA
test2 <- na.omit(test)
"test"
print(test)
students <- data.frame(people=c("Lily", "Bo", "Jen", "Omar", "Sara", "Jack", "Ting"), team=c("Red", "Blue", "Green", "Red", "Blue", "Green", "Red"), number=c(1,2,3,5,2,7,1))
View(students)
scores <- data.frame(team=c("Black", "Blue", "Green", "Indigo", "Orange", "Red", "Violet", "White", "Yellow"), score1=c(90,96,93,88,82,84,95,89,79), score2=c(5,5,4,4,5,3,5,5,3))
View(scores)
score1 <- rep(NA, 7)
score2 <- rep(NA, 7)
students <- data.frame(students, score1, score2)
students <- data.frame(people=c("Lily", "Bo", "Jen", "Omar", "Sara", "Jack", "Ting"), team=c("Red", "Blue", "Green", "Red", "Blue", "Green", "Red"), number=c(1,2,3,5,2,7,1))
students <- data.frame(students, score1, score2)
View(students)
students$score1 <- scores$score1[match(students$team, scores$team)]
View(students)
students$score2 <- scores$score2[match(students$team, scores$team)]
students$score2 <- scores$score2[match(students$team, scores$team)]
View(students)
library(ggmap)
library(ggplot2)
library(ggmap)
install.packages("ggplot2")
library(ggmap)
library(zoo)
library(extRemes)
library(fExtremes)
load("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/SLR_GEV.RData")
matplot(gev, 1-q, log= 'y', type = 'l',lty = 1, col = "black")
matplot(gev[,1], 1-q, log= 'y', type = 'l',lty = 1, col = "black")
matplot(gev[,1], 1-q, log= 'y', type = 'l',lty = 1, col = "black")
matplot(gev, 1-q, log= 'y', type = 'l',lty = 1, col = "black")
matplot(gev, 1-q, log= 'y', type = 'l',lty = 1, col = rgb(0,0,0,0.05))
dim(EV_p_exceed_transient)
hist(EV_p_exceed_transient[1,])
# Compile
rm(list = ls())
graphics.off()
library(compiler)
enableJIT(3)
# Number of observations
n_obs = 10^4
# Set prior parameter values - Section 6 "The Doubtful Constants," van Dantzig (1956)
source("../../Scripts/priors.R")
# Source parameters for sea level rise and storm surge modules
source("Scripts/sample.R")
source("Scripts/slr_OAT.R")
Parameter_PDF <- Parameters
# Create vector to change parameters from 1% to 99% quantile of PDF
quantile_prior <- seq(0.01, 0.99, by = 0.01)
# van Dantzig problem setup:
# Time horizon until next evaluation of dikes (years)
T = 75
# Initial dike height
H_0 = 4.25
# Current year
year = 2015
# Fix dike height at "optimal" level from baseline model
X = 2.6
# considered time horizon, in annual increments
time = seq(0,T,by=1)
# Define variables arrays
p_exceed                = array(NA, dim = c(length(X), length(quantile_prior)))
costs                   = array(NA, dim = c(length(X), length(quantile_prior)))
NPV_expected_losses     = array(NA, dim = c(length(X), length(quantile_prior)))
EV_p_exceed_transient   = array(NA, dim = c(length(X), length(quantile_prior)))
Total_flood_frequency   = array(NA, dim = c(length(X), length(quantile_prior)))
total_costs             = array(NA, dim = c(length(X), length(quantile_prior)))
discount_factor         = array(NA, dim = c(length(time), length(quantile_prior)))
effective_height        = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
p_exceed_transient      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
NPV_costs_flooding      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
subsidence              = array(NA, dim = c(length(time), length(quantile_prior)))
sea_level_rise          = array(NA, dim = c(length(time), length(quantile_prior)))
# Create uniform arrays for all parameters based on expected value of priors
# Load posterior modes for GEV parameters
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Vector for 4 objectives
total_costs_OAT             = array(NA, dim = c(length(quantile_prior), length(Parameters)))
costs_OAT                   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
NPV_expected_losses_OAT     = array(NA, dim = c(length(quantile_prior), length(Parameters)))
EV_p_exceed_transient_OAT   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
# Run model for by holding all parameters constant and changing one at a time
for(n in 1:6){#length(Parameters)){
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Create vector to change single parameter from 1% to 99% quantile
Parameters[n] <- sapply(1:length(quantile_prior), function(x)
{
quantile(Parameter_PDF[,n], probs = quantile_prior[x])
})
# Analyze for each considered Deike heightening (eq. 1 in paper)
for(i in 1:length(quantile_prior)) {
# Exceedance probability of current dike height
p_exceed[i]= Parameters$p_zero_p[i]*exp(-(Parameters$alpha_p[i])*X)
for (j in 1:length(time)) {
# Land subsidence over length of time horizon
subsidence[j,] = Parameters$subs_rate[i]*time[j]
# Sea level rise over length of time horizon
sea_level_rise[j,] = sea_level_global(Parameters$a[i], Parameters$b[i], Parameters$c[i], Parameters$c.star[i], (Parameters$t.star[i] - year), j) /1000 #+ res.boot_proj[i,]
# Annual discounting factor as a function of time
discount_factor[j,] = 1/(1+Parameters$delta_prime_p[i])^time[j]
# The effective dike height is the current height minus the
# combined effects of subsidence and sea-level rise
effective_height[,j,] = X - subsidence[j,] - sea_level_rise[j,]
# Annual flood frequency using old observations and new effective heights
# (assumes stationary flooding frequency)
# Annual flood frequency using old observations and new effective height (assumes stationary flooding frequency)
p_exceed_transient[,j,] = Parameters$p_zero_p[i]*exp(-(Parameters$alpha_p[i])*effective_height[,j,])
# Net Present Value of the discounted expected annual losses (damages due to flooding in a given year)
NPV_costs_flooding[,j,] = p_exceed_transient[,j,]*Parameters$V_p[i]*discount_factor[j,]
}
# The costs of flood protection (dike building) - increase linearly with respect to height
costs[i] = Parameters$k_p[i]*X
# The total discounted expected losses are the sum of the discounted expected annual losses
NPV_expected_losses[i]=sum(NPV_costs_flooding[,j,])
# Expected value of average annual flood frequency (mean of annual flood frequencies)
EV_p_exceed_transient[i]=mean(p_exceed_transient[,j,])
# The total flood frequency over the life-time of the project is the sum of the flood frequencies,
# assuming independence, as in the original paper
Total_flood_frequency[i]=sum(p_exceed_transient[,j,])
# The total costs that depend on the dike height. This analysis neglects initial mobilization
# costs (I_0) in paper, as well as any costs extending beyond considered time horizon
total_costs[i] = costs[i] + NPV_expected_losses[i]
}
# Find the index of the EUM point (minimum along total costs)
total_costs_OAT[,n] <- total_costs
costs_OAT[,n] <- costs
NPV_expected_losses_OAT[,n] <- NPV_expected_losses
EV_p_exceed_transient_OAT[,n] <- EV_p_exceed_transient
}
colnames(total_costs_OAT)             <- names(Parameters)
colnames(costs_OAT)                   <- names(Parameters)
colnames(NPV_expected_losses_OAT)     <- names(Parameters)
colnames(EV_p_exceed_transient_OAT)   <- names(Parameters)
setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT")
# Compile
rm(list = ls())
graphics.off()
library(compiler)
enableJIT(3)
# Number of observations
n_obs = 10^4
# Set prior parameter values - Section 6 "The Doubtful Constants," van Dantzig (1956)
source("../../Scripts/priors.R")
# Source parameters for sea level rise and storm surge modules
source("Scripts/sample.R")
source("Scripts/slr_OAT.R")
Parameter_PDF <- Parameters
# Create vector to change parameters from 1% to 99% quantile of PDF
quantile_prior <- seq(0.01, 0.99, by = 0.01)
# van Dantzig problem setup:
# Time horizon until next evaluation of dikes (years)
T = 75
# Initial dike height
H_0 = 4.25
# Current year
year = 2015
# Fix dike height at "optimal" level from baseline model
X = 2.6
# considered time horizon, in annual increments
time = seq(0,T,by=1)
# Define variables arrays
p_exceed                = array(NA, dim = c(length(X), length(quantile_prior)))
costs                   = array(NA, dim = c(length(X), length(quantile_prior)))
NPV_expected_losses     = array(NA, dim = c(length(X), length(quantile_prior)))
EV_p_exceed_transient   = array(NA, dim = c(length(X), length(quantile_prior)))
Total_flood_frequency   = array(NA, dim = c(length(X), length(quantile_prior)))
total_costs             = array(NA, dim = c(length(X), length(quantile_prior)))
discount_factor         = array(NA, dim = c(length(time), length(quantile_prior)))
effective_height        = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
p_exceed_transient      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
NPV_costs_flooding      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
subsidence              = array(NA, dim = c(length(time), length(quantile_prior)))
sea_level_rise          = array(NA, dim = c(length(time), length(quantile_prior)))
# Create uniform arrays for all parameters based on expected value of priors
# Load posterior modes for GEV parameters
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Vector for 4 objectives
total_costs_OAT             = array(NA, dim = c(length(quantile_prior), length(Parameters)))
costs_OAT                   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
NPV_expected_losses_OAT     = array(NA, dim = c(length(quantile_prior), length(Parameters)))
EV_p_exceed_transient_OAT   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
# Run model for by holding all parameters constant and changing one at a time
for(n in 1:6){#length(Parameters)){
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Create vector to change single parameter from 1% to 99% quantile
Parameters[n] <- sapply(1:length(quantile_prior), function(x)
{
quantile(Parameter_PDF[,n], probs = quantile_prior[x])
})
# Analyze for each considered Deike heightening (eq. 1 in paper)
for(i in 1:length(quantile_prior)) {
# Exceedance probability of current dike height
p_exceed[i]= Parameters$p_zero_p[i]*exp(-(Parameters$alpha_p[i])*X)
for (j in 1:length(time)) {
# Land subsidence over length of time horizon
subsidence[j,] = Parameters$subs_rate[i]*time[j]
# Sea level rise over length of time horizon
sea_level_rise[j,] = sea_level_global(Parameters$a[i], Parameters$b[i], Parameters$c[i], Parameters$c.star[i], (Parameters$t.star[i] - year), j) /1000 #+ res.boot_proj[i,]
# Annual discounting factor as a function of time
discount_factor[j,] = 1/(1+Parameters$delta_prime_p[i])^time[j]
# The effective dike height is the current height minus the
# combined effects of subsidence and sea-level rise
effective_height[,j,] = X - subsidence[j,] - sea_level_rise[j,]
# Annual flood frequency using old observations and new effective heights
# (assumes stationary flooding frequency)
# Annual flood frequency using old observations and new effective height (assumes stationary flooding frequency)
p_exceed_transient[,j,] = Parameters$p_zero_p[i]*exp(-(Parameters$alpha_p[i])*effective_height[,j,])
# Net Present Value of the discounted expected annual losses (damages due to flooding in a given year)
NPV_costs_flooding[,j,] = p_exceed_transient[,j,]*Parameters$V_p[i]*discount_factor[j,]
}
# The costs of flood protection (dike building) - increase linearly with respect to height
costs[i] = Parameters$k_p[i]*X
# The total discounted expected losses are the sum of the discounted expected annual losses
NPV_expected_losses[i]=sum(NPV_costs_flooding[,j,])
# Expected value of average annual flood frequency (mean of annual flood frequencies)
EV_p_exceed_transient[i]=mean(p_exceed_transient[,j,])
# The total flood frequency over the life-time of the project is the sum of the flood frequencies,
# assuming independence, as in the original paper
Total_flood_frequency[i]=sum(p_exceed_transient[,j,])
# The total costs that depend on the dike height. This analysis neglects initial mobilization
# costs (I_0) in paper, as well as any costs extending beyond considered time horizon
total_costs[i] = costs[i] + NPV_expected_losses[i]
}
# Find the index of the EUM point (minimum along total costs)
total_costs_OAT[,n] <- total_costs
costs_OAT[,n] <- costs
NPV_expected_losses_OAT[,n] <- NPV_expected_losses
EV_p_exceed_transient_OAT[,n] <- EV_p_exceed_transient
}
colnames(total_costs_OAT)             <- names(Parameters)
colnames(costs_OAT)                   <- names(Parameters)
colnames(NPV_expected_losses_OAT)     <- names(Parameters)
colnames(EV_p_exceed_transient_OAT)   <- names(Parameters)
View(sea_level_rise)
###################################
# file: OAT_SLR.R
###################################
# Author and copyright: Perry Oddo
# Pennsylvania State University
# poddo@psu.edu
###################################
# One-at-a-time sensitivity analysis
# for van Dantzig (1956) model
####################################
# Set working directory
#setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT")
# Compile
rm(list = ls())
graphics.off()
library(compiler)
enableJIT(3)
# Number of observations
n_obs = 10^4
# Set prior parameter values - Section 6 "The Doubtful Constants," van Dantzig (1956)
source("../../Scripts/priors.R")
# Source parameters for sea level rise and storm surge modules
source("Scripts/sample.R")
source("Scripts/slr_OAT.R")
Parameter_PDF <- Parameters
# Create vector to change parameters from 1% to 99% quantile of PDF
quantile_prior <- seq(0.01, 0.99, by = 0.01)
# van Dantzig problem setup:
# Time horizon until next evaluation of dikes (years)
T = 75
# Initial dike height
H_0 = 4.25
# Current year
year = 2015
# Fix dike height at "optimal" level from baseline model
X = 2.6
# considered time horizon, in annual increments
time = seq(0,T,by=1)
# Define variables arrays
p_exceed                = array(NA, dim = c(length(X), length(quantile_prior)))
costs                   = array(NA, dim = c(length(X), length(quantile_prior)))
NPV_expected_losses     = array(NA, dim = c(length(X), length(quantile_prior)))
EV_p_exceed_transient   = array(NA, dim = c(length(X), length(quantile_prior)))
Total_flood_frequency   = array(NA, dim = c(length(X), length(quantile_prior)))
total_costs             = array(NA, dim = c(length(X), length(quantile_prior)))
discount_factor         = array(NA, dim = c(length(time), length(quantile_prior)))
effective_height        = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
p_exceed_transient      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
NPV_costs_flooding      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
subsidence              = array(NA, dim = c(length(time), length(quantile_prior)))
sea_level_rise          = array(NA, dim = c(length(time), length(quantile_prior)))
# Create uniform arrays for all parameters based on expected value of priors
# Load posterior modes for GEV parameters
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Vector for 4 objectives
total_costs_OAT             = array(NA, dim = c(length(quantile_prior), length(Parameters)))
costs_OAT                   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
NPV_expected_losses_OAT     = array(NA, dim = c(length(quantile_prior), length(Parameters)))
EV_p_exceed_transient_OAT   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
# Run model for by holding all parameters constant and changing one at a time
for(n in 1:6){#length(Parameters)){
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Create vector to change single parameter from 1% to 99% quantile
Parameters[n] <- sapply(1:length(quantile_prior), function(x)
{
quantile(Parameter_PDF[,n], probs = quantile_prior[x])
})
# Analyze for each considered Deike heightening (eq. 1 in paper)
for(i in 1:length(quantile_prior)) {
# Exceedance probability of current dike height
p_exceed[i]= Parameters$p_zero_p[i]*exp(-(Parameters$alpha_p[i])*X)
for (j in 1:length(time)) {
# Land subsidence over length of time horizon
subsidence[j,i] = Parameters$subs_rate[i]*time[j]
# Sea level rise over length of time horizon
sea_level_rise[j,i] = sea_level_global(Parameters$a[i], Parameters$b[i], Parameters$c[i], Parameters$c.star[i], (Parameters$t.star[i] - year), j) /1000 #+ res.boot_proj[i,]
# Annual discounting factor as a function of time
discount_factor[j,i] = 1/(1+Parameters$delta_prime_p[i])^time[j]
# The effective dike height is the current height minus the
# combined effects of subsidence and sea-level rise
effective_height[,j,] = X - subsidence[j,] - sea_level_rise[j,]
# Annual flood frequency using old observations and new effective heights
# (assumes stationary flooding frequency)
# Annual flood frequency using old observations and new effective height (assumes stationary flooding frequency)
p_exceed_transient[,j,] = Parameters$p_zero_p[i]*exp(-(Parameters$alpha_p[i])*effective_height[,j,])
# Net Present Value of the discounted expected annual losses (damages due to flooding in a given year)
NPV_costs_flooding[,j,] = p_exceed_transient[,j,]*Parameters$V_p[i]*discount_factor[j,]
}
# The costs of flood protection (dike building) - increase linearly with respect to height
costs[i] = Parameters$k_p[i]*X
# The total discounted expected losses are the sum of the discounted expected annual losses
NPV_expected_losses[i]=sum(NPV_costs_flooding[,j,])
# Expected value of average annual flood frequency (mean of annual flood frequencies)
EV_p_exceed_transient[i]=mean(p_exceed_transient[,j,])
# The total flood frequency over the life-time of the project is the sum of the flood frequencies,
# assuming independence, as in the original paper
Total_flood_frequency[i]=sum(p_exceed_transient[,j,])
# The total costs that depend on the dike height. This analysis neglects initial mobilization
# costs (I_0) in paper, as well as any costs extending beyond considered time horizon
total_costs[i] = costs[i] + NPV_expected_losses[i]
}
# Find the index of the EUM point (minimum along total costs)
total_costs_OAT[,n] <- total_costs
costs_OAT[,n] <- costs
NPV_expected_losses_OAT[,n] <- NPV_expected_losses
EV_p_exceed_transient_OAT[,n] <- EV_p_exceed_transient
}
colnames(total_costs_OAT)             <- names(Parameters)
colnames(costs_OAT)                   <- names(Parameters)
colnames(NPV_expected_losses_OAT)     <- names(Parameters)
colnames(EV_p_exceed_transient_OAT)   <- names(Parameters)
View(Parameters)
View(sea_level_rise)
View(subsidence)
View(effective_height[1,,])
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT/OAT_SLR_GEV.R', echo=TRUE)
setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT")
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT/OAT_SLR_GEV.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT/OAT_SLR_GEV.R', echo=TRUE)
View(costs_OAT)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT/OAT_SLR_GEV.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT/OAT_SLR_GEV.R', echo=TRUE)
