matplot(gev, 1-q, log= 'y', type = 'l',lty = 1, col = rgb(0,0,0,0.05))
dim(EV_p_exceed_transient)
hist(EV_p_exceed_transient[1,])
setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV")
###################################
# file: vanDantzig_SLR_GEV.R
###################################
# Author and copyright: Perry Oddo
# Pennsylvania State University
# poddo@psu.edu
#
# Distributed under GNU general public license
# No warranty
#
# Adapted from: cost-benefit-slr.R
# Authored by Ryan Sriver and Klaus Keller
# Pennsylvania State University
#
# Based on: van Dantzig D (1956). Economic Decision Problems for flood prevention.
# Econometrica 24:276-287
###################################
# Last modified: 16 September, 2015
###################################
# Set working directory
#setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV")
# Compile
rm(list = ls())
graphics.off()
library(compiler)
enableJIT(3)
# Set seed for reproducibility
set.seed(1)
# Number of observations
n_obs = 10^4
# Prior parameter values - Section 6 "The Doubtful Constants," van Dantzig (1956)
source("Scripts/priors.R")
# p_zero_p = 0.0038         # Initial flood frequency (1/yr) with zero height increase
# alpha_p = 2.6             # Exponential flood frequency constant
# V_p = 2 * 1e+10           # Value of goods protected by dike (includes "factor of 2" for cost of human life - Section 7)
# delta_prime_p = 0.02      # Discount rate (percent/year)
# k_p = 4.2e7               # Cost of heightening dikes by 1 meter
# subs_rate = 0.002         # Rate of land subsidence (meter/year)
# sea_level_rate = 0.008    # Rate of sea level rise (meter/year)
# Sample parameters with LHS function
# Creates data.frame with parameter PDFs
source("Scripts/LHS.R")
# Source sea level rise module
source("SLR_Module/Scripts/slr_vanDantzig.R")
# Source GEV storm surge module
source("Storm_Surge_Module/Scripts/exceedance_prob.R")
###################################
###  van Dantzig problem setup  ###
###################################
# Current year
year = 2015
# Time horizon until next evaluation of dikes (years)
T = 75
# Range of considerend dike heights (meters)
X = seq(0, 10, by=0.05)
# Initial dike height
H_0 = 4.25
# Time horizon in annual increments
time = seq(0, T, by=1)
# Initialize variables arrays
p_exceed                = array(NA, dim = c(length(X), n_obs))
costs                   = array(NA, dim = c(length(X), n_obs))
NPV_expected_losses     = array(NA, dim = c(length(X), n_obs))
EV_p_exceed_transient   = array(NA, dim = c(length(X), n_obs))
Total_flood_frequency   = array(NA, dim = c(length(X), n_obs))
total_costs             = array(NA, dim = c(length(X), n_obs))
discount_factor         = array(NA, dim = c(length(time), n_obs))
effective_height        = array(NA, dim = c(length(X), length(time), n_obs))
p_exceed_transient      = array(NA, dim = c(length(X), length(time), n_obs))
NPV_costs_flooding      = array(NA, dim = c(length(X), length(time), n_obs))
subsidence              = array(NA, dim = c(length(time), n_obs))
# Run model for 10,000 SOW
# Analyze for each considered Deike heightening (eq. 1 in paper)
# Exceedance probability of current dike height (4.25 meters - Section 6)
p_exceed = t(sapply(1:length(X), function(i){
exceedance_prob(X[i] + H_0)   }))
# Land subsidence over length of time horizon
subsidence = t(sapply(1:length(time), function(j) {
Parameters$subs_rate * time[j]   }))
# Sea level rise over length of time horizon
sea_level_rise = t(sapply(1:length(time), function(j) {
sea_level_global(beta.dist$a, beta.dist$b, beta.dist$c, beta.dist$c.star, (beta.dist$t.star - year), j) /1000  }))#+ res.boot_proj[i,]
# Annual discounting factor as a function of time
discount_factor = t(sapply(1:length(time), function(j) {
1/(1+Parameters$delta_prime_p)^time[j]   }))
# The effective dike height is the current height minus the
# combined effects of subsidence and sea-level rise
effective_height[,,] = t(sapply(1:length(X), function(i) {
t(sapply(1:length(time), function(j) {
X[i] - subsidence[j,] - sea_level_rise[j,]    }))   }))
View(discount_factor)
View(EV_p_exceed_transient)
View(sea_level_rise)
matplot(1:76, sea_level_rise[,1:50], type = 'l', lty = 1, col = "black")
lines(1:76, sea_level_rate*(1:76), lty = 1, col = "red")
lines(1:76, sea_level_rate*(1:76), lty = 1, col = "red", lwd = 4)
lines(1:76, apply(sea_level_rise, 1, mean), col = "blue", lwd = 4)
View(subsidence)
matplot(1:76, subsidence, type = 'l', lty = 1, col = rgb(0,0,0,0.04))
load("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/vanDantzig_SLR_GEV.R")
load("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/SLR_GEV.RData")
min_cost_X_mean
setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT")
###################################
# file: OAT_SLR.R
###################################
# Author and copyright: Perry Oddo
# Pennsylvania State University
# poddo@psu.edu
###################################
# One-at-a-time sensitivity analysis
# for van Dantzig (1956) model
####################################
# Set working directory
#setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT")
# Compile
rm(list = ls())
graphics.off()
library(compiler)
enableJIT(3)
# Number of observations
n_obs = 10^4
# Set prior parameter values - Section 6 "The Doubtful Constants," van Dantzig (1956)
source("../../Scripts/priors.R")
# Source parameters for sea level rise and storm surge modules
source("Scripts/sample.R")
source("Scripts/slr_OAT.R")
Parameter_PDF <- Parameters
# Create vector to change parameters from 1% to 99% quantile of PDF
quantile_prior <- seq(0.01, 0.99, by = 0.01)
# van Dantzig problem setup:
# Time horizon until next evaluation of dikes (years)
T = 75
# Initial dike height
H_0 = 4.25
# Current year
year = 2015
# Fix dike height at "optimal" level from baseline model
X = 2.6
# considered time horizon, in annual increments
time = seq(0,T,by=1)
# Define variables arrays
p_exceed                = array(NA, dim = c(length(X), length(quantile_prior)))
costs                   = array(NA, dim = c(length(X), length(quantile_prior)))
NPV_expected_losses     = array(NA, dim = c(length(X), length(quantile_prior)))
EV_p_exceed_transient   = array(NA, dim = c(length(X), length(quantile_prior)))
Total_flood_frequency   = array(NA, dim = c(length(X), length(quantile_prior)))
total_costs             = array(NA, dim = c(length(X), length(quantile_prior)))
discount_factor         = array(NA, dim = c(length(time), length(quantile_prior)))
effective_height        = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
p_exceed_transient      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
NPV_costs_flooding      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
subsidence              = array(NA, dim = c(length(time), length(quantile_prior)))
sea_level_rise          = array(NA, dim = c(length(time), length(quantile_prior)))
# Create uniform arrays for all parameters based on expected value of priors
# Load posterior modes for GEV parameters
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Vector for 4 objectives
total_costs_OAT             = array(NA, dim = c(length(quantile_prior), length(Parameters)))
costs_OAT                   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
NPV_expected_losses_OAT     = array(NA, dim = c(length(quantile_prior), length(Parameters)))
EV_p_exceed_transient_OAT   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
# Run model for by holding all parameters constant and changing one at a time
for(n in 1:length(Parameters)){
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Create vector to change single parameter from 1% to 99% quantile
Parameters[n] <- sapply(1:length(quantile_prior), function(x)
{
quantile(Parameter_PDF[,n], probs = quantile_prior[x])
})
# Analyze for each considered Deike heightening (eq. 1 in paper)
# Exceedance probability of current dike height
p_exceed = t(sapply(1:length(X), function(i) {
Parameters$p_zero_p * exp(-(Parameters$alpha_p) * X[i])   }))
# Land subsidence over length of time horizon
subsidence = t(sapply(1:length(time), function(j) {
Parameters$subs_rate * time[j]   }))
# Sea level rise over length of time horizon
sea_level_rise = t(sapply(1:length(time), function(j) {
sea_level_global(Parameters$a, Parameters$b, Parameters$c, Parameters$c.star, (Parameters$t.star - year), j) /1000  }))#+ res.boot_proj[i,]
# Annual discounting factor as a function of time
discount_factor = t(sapply(1:length(time), function(j) {
1/(1+Parameters$delta_prime_p)^time[j]   }))
# The effective dike height is the current height minus the
# combined effects of subsidence and sea-level rise
effective_height[,,] = t(sapply(1:length(X), function(i) {
t(sapply(1:length(time), function(j) {
X[i] - subsidence[j,] - sea_level_rise[j,]    }))   }))
# Annual flood frequency using old observations and new effective height
# (assumes stationary flooding frequency)
p_exceed_transient[,,] = t(sapply(1:length(X), function(i) {
t(sapply(1:length(time), function(j) {
Parameters$p_zero_p * exp(-(Parameters$alpha_p) * effective_height[i,j,])   }))   }))
# Net Present Value of the discounted expected annual losses (damages due to flooding in a given year)
NPV_costs_flooding[,,] = t(sapply(1:length(X), function(i) {
t(sapply(1:length(time), function(j) {
p_exceed_transient[i,j,]*Parameters$V_p*discount_factor[j,]   }))   }))
# The costs of flood protection (dike building) - increase linearly with respect to height
costs = t(sapply(1:length(X), function(i) {
Parameters$k_p * X[i]   }))
# The total discounted expected losses are the sum of the discounted expected annual losses
NPV_expected_losses = apply(NPV_costs_flooding, c(1,3), sum)
# Expected value of average annual flood frequency (mean of annual flood frequencies)
EV_p_exceed_transient = apply(p_exceed_transient, c(1,3), mean)
# The total flood frequency over the life-time of the project is the sum of the flood frequencies,
# assuming independence, as in the original paper
Total_flood_frequency = apply(p_exceed_transient, c(1,3), sum)
# The total costs that depend on the dike height. This analysis neglects initial mobilization
# costs (I_0) in paper, as well as any costs extending beyond considered time horizon
total_costs = t(sapply(1:length(X), function(i) {
costs[i,] + NPV_expected_losses[i,]   }))
# Find the index of the EUM point (minimum along total costs)
total_costs_OAT[,n] <- total_costs
costs_OAT[,n] <- costs
NPV_expected_losses_OAT[,n] <- NPV_expected_losses
EV_p_exceed_transient_OAT[,n] <- EV_p_exceed_transient
}
colnames(total_costs_OAT)             <- names(Parameters)
colnames(costs_OAT)                   <- names(Parameters)
colnames(NPV_expected_losses_OAT)     <- names(Parameters)
colnames(EV_p_exceed_transient_OAT)   <- names(Parameters)
View(EV_p_exceed_transient)
View(EV_p_exceed_transient_OAT)
setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT")
###################################
# file: OAT_SLR.R
###################################
# Author and copyright: Perry Oddo
# Pennsylvania State University
# poddo@psu.edu
###################################
# One-at-a-time sensitivity analysis
# for van Dantzig (1956) model
####################################
# Set working directory
#setwd("~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR_GEV/Sensitivity_Analysis/OAT")
# Compile
rm(list = ls())
graphics.off()
library(compiler)
enableJIT(3)
# Number of observations
n_obs = 10^4
# Set prior parameter values - Section 6 "The Doubtful Constants," van Dantzig (1956)
source("../../Scripts/priors.R")
# Source parameters for sea level rise and storm surge modules
source("Scripts/sample.R")
source("Scripts/slr_OAT.R")
Parameter_PDF <- Parameters
# Create vector to change parameters from 1% to 99% quantile of PDF
quantile_prior <- seq(0.01, 0.99, by = 0.01)
# van Dantzig problem setup:
# Time horizon until next evaluation of dikes (years)
T = 75
# Initial dike height
H_0 = 4.25
# Current year
year = 2015
# Fix dike height at "optimal" level from baseline model
X = 2.35
# considered time horizon, in annual increments
time = seq(0,T,by=1)
# Define variables arrays
p_exceed                = array(NA, dim = c(length(X), length(quantile_prior)))
costs                   = array(NA, dim = c(length(X), length(quantile_prior)))
NPV_expected_losses     = array(NA, dim = c(length(X), length(quantile_prior)))
EV_p_exceed_transient   = array(NA, dim = c(length(X), length(quantile_prior)))
Total_flood_frequency   = array(NA, dim = c(length(X), length(quantile_prior)))
total_costs             = array(NA, dim = c(length(X), length(quantile_prior)))
discount_factor         = array(NA, dim = c(length(time), length(quantile_prior)))
effective_height        = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
p_exceed_transient      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
NPV_costs_flooding      = array(NA, dim = c(length(X), length(time), length(quantile_prior)))
subsidence              = array(NA, dim = c(length(time), length(quantile_prior)))
sea_level_rise          = array(NA, dim = c(length(time), length(quantile_prior)))
# Create uniform arrays for all parameters based on expected value of priors
# Load posterior modes for GEV parameters
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Vector for 4 objectives
total_costs_OAT             = array(NA, dim = c(length(quantile_prior), length(Parameters)))
costs_OAT                   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
NPV_expected_losses_OAT     = array(NA, dim = c(length(quantile_prior), length(Parameters)))
EV_p_exceed_transient_OAT   = array(NA, dim = c(length(quantile_prior), length(Parameters)))
# Run model for by holding all parameters constant and changing one at a time
for(n in 1:length(Parameters)){
p_zero_p        = array(priors$p_zero_p, length(quantile_prior))
alpha_p         = array(priors$alpha_p, length(quantile_prior))
V_p             = array(priors$V_p, length(quantile_prior))
delta_prime_p   = array(priors$delta_prime_p, length(quantile_prior))
k_p             = array(priors$k_p, length(quantile_prior))
subs_rate       = array(priors$subs_rate, length(quantile_prior))
a               = array(mean(Parameters$a), length(quantile_prior))
b               = array(mean(Parameters$b), length(quantile_prior))
c               = array(mean(Parameters$c), length(quantile_prior))
t.star          = array(mean(Parameters$t.star), length(quantile_prior))
c.star          = array(mean(Parameters$c.star), length(quantile_prior))
Parameters <- data.frame(p_zero_p, alpha_p, V_p, delta_prime_p, k_p, subs_rate, a, b, c, t.star, c.star)
# Create vector to change single parameter from 1% to 99% quantile
Parameters[n] <- sapply(1:length(quantile_prior), function(x)
{
quantile(Parameter_PDF[,n], probs = quantile_prior[x])
})
# Analyze for each considered Deike heightening (eq. 1 in paper)
# Exceedance probability of current dike height
p_exceed = t(sapply(1:length(X), function(i) {
Parameters$p_zero_p * exp(-(Parameters$alpha_p) * X[i])   }))
# Land subsidence over length of time horizon
subsidence = t(sapply(1:length(time), function(j) {
Parameters$subs_rate * time[j]   }))
# Sea level rise over length of time horizon
sea_level_rise = t(sapply(1:length(time), function(j) {
sea_level_global(Parameters$a, Parameters$b, Parameters$c, Parameters$c.star, (Parameters$t.star - year), j) /1000  }))#+ res.boot_proj[i,]
# Annual discounting factor as a function of time
discount_factor = t(sapply(1:length(time), function(j) {
1/(1+Parameters$delta_prime_p)^time[j]   }))
# The effective dike height is the current height minus the
# combined effects of subsidence and sea-level rise
effective_height[,,] = t(sapply(1:length(X), function(i) {
t(sapply(1:length(time), function(j) {
X[i] - subsidence[j,] - sea_level_rise[j,]    }))   }))
# Annual flood frequency using old observations and new effective height
# (assumes stationary flooding frequency)
p_exceed_transient[,,] = t(sapply(1:length(X), function(i) {
t(sapply(1:length(time), function(j) {
Parameters$p_zero_p * exp(-(Parameters$alpha_p) * effective_height[i,j,])   }))   }))
# Net Present Value of the discounted expected annual losses (damages due to flooding in a given year)
NPV_costs_flooding[,,] = t(sapply(1:length(X), function(i) {
t(sapply(1:length(time), function(j) {
p_exceed_transient[i,j,]*Parameters$V_p*discount_factor[j,]   }))   }))
# The costs of flood protection (dike building) - increase linearly with respect to height
costs = t(sapply(1:length(X), function(i) {
Parameters$k_p * X[i]   }))
# The total discounted expected losses are the sum of the discounted expected annual losses
NPV_expected_losses = apply(NPV_costs_flooding, c(1,3), sum)
# Expected value of average annual flood frequency (mean of annual flood frequencies)
EV_p_exceed_transient = apply(p_exceed_transient, c(1,3), mean)
# The total flood frequency over the life-time of the project is the sum of the flood frequencies,
# assuming independence, as in the original paper
Total_flood_frequency = apply(p_exceed_transient, c(1,3), sum)
# The total costs that depend on the dike height. This analysis neglects initial mobilization
# costs (I_0) in paper, as well as any costs extending beyond considered time horizon
total_costs = t(sapply(1:length(X), function(i) {
costs[i,] + NPV_expected_losses[i,]   }))
# Find the index of the EUM point (minimum along total costs)
total_costs_OAT[,n] <- total_costs
costs_OAT[,n] <- costs
NPV_expected_losses_OAT[,n] <- NPV_expected_losses
EV_p_exceed_transient_OAT[,n] <- EV_p_exceed_transient
}
colnames(total_costs_OAT)             <- names(Parameters)
colnames(costs_OAT)                   <- names(Parameters)
colnames(NPV_expected_losses_OAT)     <- names(Parameters)
colnames(EV_p_exceed_transient_OAT)   <- names(Parameters)
############################
### Tornado diagram
# Determine total parameter ranges for each Objective
costs_range <- sapply(1:length(Parameters), function(x){
max(costs_OAT[,x]) - min(costs_OAT[,x])
})
NPV_expected_losses_range <- sapply(1:length(Parameters), function(x){
max(NPV_expected_losses_OAT[,x]) - min(NPV_expected_losses_OAT[,x])
})
EV_p_exceed_transient_range <- sapply(1:length(Parameters), function(x){
max(EV_p_exceed_transient_OAT[,x]) - min(EV_p_exceed_transient_OAT[,x])
})
total_costs_range <- sapply(1:length(Parameters), function(x){
max(total_costs_OAT[,x]) - min(total_costs_OAT[,x])
})
names(costs_range) <- names(Parameters)
names(NPV_expected_losses_range) <- names(Parameters)
names(EV_p_exceed_transient_range) <- names(Parameters)
names(total_costs_range) <- names(Parameters)
# Determine percentage of total range above and below 50% quantile (center point)
# Below (quantile 50 - quantile 1)
costs_range_minus <- sapply(1:length(Parameters), function(x) {
abs((costs_OAT[50,x] - costs_OAT[1,x]) / costs_range[x])
})
NPV_expected_losses_range_minus <- sapply(1:length(Parameters), function(x) {
abs((NPV_expected_losses_OAT[50,x] - NPV_expected_losses_OAT[1,x]) / NPV_expected_losses_range[x])
})
EV_p_exceed_transient_range_minus <- sapply(1:length(Parameters), function(x) {
abs((EV_p_exceed_transient_OAT[50,x] - EV_p_exceed_transient_OAT[1,x]) / EV_p_exceed_transient_range[x])
})
total_costs_range_minus <- sapply(1:length(Parameters), function(x) {
abs((total_costs_OAT[50,x] - total_costs_OAT[1,x]) / total_costs_range[x])
})
# Above (quantile 99 - quantile 50)
costs_range_plus <- sapply(1:length(Parameters), function(x) {
abs((costs_OAT[99,x] - costs_OAT[50,x]) / costs_range[x])
})
NPV_expected_losses_range_plus <- sapply(1:length(Parameters), function(x) {
abs((NPV_expected_losses_OAT[99,x] - NPV_expected_losses_OAT[50,x]) / NPV_expected_losses_range[x])
})
EV_p_exceed_transient_range_plus <- sapply(1:length(Parameters), function(x) {
abs((EV_p_exceed_transient_OAT[99,x] - EV_p_exceed_transient_OAT[50,x]) / EV_p_exceed_transient_range[x])
})
total_costs_range_plus <- sapply(1:length(Parameters), function(x) {
abs((total_costs_OAT[99,x] - total_costs_OAT[50,x]) / total_costs_range[x])
})
# Normalize total range to 1 by dividing by largest range in each series
costs_range                   = costs_range/max(costs_range)
NPV_expected_losses_range     = NPV_expected_losses_range/max(NPV_expected_losses_range)
EV_p_exceed_transient_range   = EV_p_exceed_transient_range/max(EV_p_exceed_transient_range)
total_costs_range             = total_costs_range/max(total_costs_range)
# Normalize 50% +/- vectors to 1
# This makes each variance a fraction of the largest range, as well as showing what percentage
# of each range lies above and below the center line
for(i in 1:length(Parameters)){
costs_range_plus[i] = costs_range_plus[i] * costs_range[i]
costs_range_minus[i] = costs_range_minus[i] * costs_range[i]
NPV_expected_losses_range_plus[i] = NPV_expected_losses_range_plus[i] * NPV_expected_losses_range[i]
NPV_expected_losses_range_minus[i] = NPV_expected_losses_range_minus[i] * NPV_expected_losses_range[i]
EV_p_exceed_transient_range_plus[i] = EV_p_exceed_transient_range_plus[i] * EV_p_exceed_transient_range[i]
EV_p_exceed_transient_range_minus[i] = EV_p_exceed_transient_range_minus[i] * EV_p_exceed_transient_range[i]
total_costs_range_plus[i] = total_costs_range_plus[i] * total_costs_range[i]
total_costs_range_minus[i] = total_costs_range_minus[i] * total_costs_range[i]
}
# Sort the full ranges in decreasing order
costs_range                   = sort(costs_range, decreasing = TRUE)
NPV_expected_losses_range     = sort(NPV_expected_losses_range, decreasing = TRUE)
EV_p_exceed_transient_range   = sort(EV_p_exceed_transient_range, decreasing = TRUE)
total_costs_range             = sort(total_costs_range, decreasing = TRUE)
# Sort the plus/minus vectors so they represent the same decreasing order as the full range
costs_range_plus = costs_range_plus[order(match(names(costs_range_plus), names(costs_range)))]
costs_range_minus = costs_range_minus[order(match(names(costs_range_minus), names(costs_range)))]
NPV_expected_losses_range_plus = NPV_expected_losses_range_plus[order(match(names(NPV_expected_losses_range_plus), names(NPV_expected_losses_range)))]
NPV_expected_losses_range_minus = NPV_expected_losses_range_minus[order(match(names(NPV_expected_losses_range_minus), names(NPV_expected_losses_range)))]
EV_p_exceed_transient_range_plus = EV_p_exceed_transient_range_plus[order(match(names(EV_p_exceed_transient_range_plus), names(EV_p_exceed_transient_range)))]
EV_p_exceed_transient_range_minus = EV_p_exceed_transient_range_minus[order(match(names(EV_p_exceed_transient_range_minus), names(EV_p_exceed_transient_range)))]
total_costs_range_plus = total_costs_range_plus[order(match(names(total_costs_range_plus), names(total_costs_range)))]
total_costs_range_minus = total_costs_range_minus[order(match(names(total_costs_range_minus), names(total_costs_range)))]
### Plot results
# Set up matrix for positioning polygons
start = matrix(0, nrow = length(Parameters), ncol = 2)
start[1,] = c(0,1)
space = 0.25  # Space between bars
width = 0.15  # Width of bars
for(i in 2:length(Parameters)){
start[i,2] = start[i-1,2] - space
}
# Set up matrix for plotting text in figure margins
lab_text = start
lab_text[1:length(Parameters),1] = 1.15
for(i in 1:length(Parameters)){
lab_text[i,2] = start[i,2]-(width/2)
}
costs_range
NPV_expected_losses_range
EV_p_exceed_transient_range
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
source('~/Documents/Grad/SCRiM/vanDantzig/Model_Versions/Uncertainty_SLR/Sensitivity_Analysis/OAT/OAT_SLR.R', echo=TRUE)
alpha <- seq(1, 0.25, length.out = 76)
plot(density(p_exceed_transient[1,1,]), main = NA, lwd = 1,
xlim = c(0,0.55), xlab = "Annual flood frequency [1/yr]")
for(i in 1:76){
lines(density(p_exceed_transient[1,i,]), lwd = 1, col = rgb(0,0,0,alpha[i]))
}
arrows(0.15, 22, 0.45, 22, lwd = 2)
text(0.3, 27, labels = "Time \n[1-75 years]")
box(lwd = 1.5)
plot(density(Parameters$p_zero_p), xlab = "Initial flood frequency [1/yr]", xlim = c(0,0.11), )
abline(v = p_zero_p, lwd = 3, col = "gray")
lines(density(p_exceed[1,]))
lines(hist(Parameters$p_zero_p))
par(mfrow = c(1,2), mar = c(4,4, 2, 1), oma = c(0,0,0,0)+0.1)
hist(Parameters$p_zero_p, xlab = "Initial flood frequency",
main = NULL, border = NA, col = myblue)
abline(v = p_zero_p, col = "gray", lwd = 5)
box(lwd = 1.5)
