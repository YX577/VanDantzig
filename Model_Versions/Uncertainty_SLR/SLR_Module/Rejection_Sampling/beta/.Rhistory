col = "blue",                                # "col" = color. R has multiple colors built in that can be called by name
pch = 19,
cex = 0.5,
lwd = 2)
legend(x="topleft",                                 # "legend" creates a legend. "Topleft" indicates location on plot
inset=c(0.05,0.1),                           # inset the legend into graph
legend=c("Boric Acid", "Borate Ion"),        # sets the name for the elements in the legend
col=c("black","blue"),
lty=c("solid","dashed"),                     # sets linetypes for legend. "solid" corresponds with "Boric Acid"
lwd=c(2,2,2)
)
box(lwd = 2)                                        # "box" just puts a box outline around the plot. Here I wanted to make the outline thicker
test <- seq(1,10, 1)
plot(rnorm(100))
plot(rnorm(100), col = "red")
plot(hist(rnorm(100)))
plot(hist(rnorm(100)))
plot(rnorm(100))
point(rnorm(1000), col = "green")
points(rnorm(1000), col = "green")
?rm.NA
a <- seq(1,20, 1)
b = function(x){
a^2 + 2*a + 2
}
b = function(a){
a^2 + 2*a + 2
}
b
b(a)
plot(a, b(a))
plot(b(a), b(a)/2*b(a))
test <- rnorm(100)
test[100:120] = NA
View(test)
test2 <- sample(test, 1000)
test2 <- sample(test, 1000, replace = T)
View(test2)
?sample
?if
?if
else
help(if)
test2 <- if test =/ NA, sample(test, 1000, replace = T)
?na.omit
test2 <- na.omit(test)
View(test2)
test <- rnorm(100)
test[101:120] = NA
test2 <- na.omit(test)
"test"
print(test)
students <- data.frame(people=c("Lily", "Bo", "Jen", "Omar", "Sara", "Jack", "Ting"), team=c("Red", "Blue", "Green", "Red", "Blue", "Green", "Red"), number=c(1,2,3,5,2,7,1))
View(students)
scores <- data.frame(team=c("Black", "Blue", "Green", "Indigo", "Orange", "Red", "Violet", "White", "Yellow"), score1=c(90,96,93,88,82,84,95,89,79), score2=c(5,5,4,4,5,3,5,5,3))
View(scores)
score1 <- rep(NA, 7)
score2 <- rep(NA, 7)
students <- data.frame(students, score1, score2)
students <- data.frame(people=c("Lily", "Bo", "Jen", "Omar", "Sara", "Jack", "Ting"), team=c("Red", "Blue", "Green", "Red", "Blue", "Green", "Red"), number=c(1,2,3,5,2,7,1))
students <- data.frame(students, score1, score2)
View(students)
students$score1 <- scores$score1[match(students$team, scores$team)]
View(students)
students$score2 <- scores$score2[match(students$team, scores$team)]
students$score2 <- scores$score2[match(students$team, scores$team)]
View(students)
library(ggmap)
library(ggplot2)
library(ggmap)
install.packages("ggplot2")
library(ggmap)
library(zoo)
library(extRemes)
library(fExtremes)
setwd("~/Documents/Grad/SCRiM/Scripts/Rejection Sampling/clean_version_rls_2011.12.6/beta")
rm(list = ls(all = TRUE))
set.seed(1) # set the seed to be reproducible
library(timeSeries)
# Define the number of bootstrap/mc samples
N=55000  # Used throughout analysis
# read in the global data from Jevrejava
raw.global<- scan(file="../data/jevrejava_yearly.txt",
what=numeric(), quiet=T)
slr.global.data <- matrix(raw.global, ncol=2, byrow=T)
years.global=slr.global.data[,1]
years.global=years.global-(2011)  # normalize time series to current year 2011
nyears.global=length(years.global)
slr.global=slr.global.data[,2]
fit.global=lm(slr.global ~ years.global + I(years.global^2))
?I
fit.global
plot.new()
plot(1)
abline(fit.global)
?lm
predict.global.2000=predict(fit.global,newdata=data.frame(years.global=-11))
View(predict.global.2000)
data.frame(years.global=-11)
slr.global=slr.global-predict.global.2000		# data
predict.hind=predict(fit.global)-predict.global.2000	# poly fit
slr.global
plot(slr.global)
max(slr.global)
predict.hind=predict(fit.global)-predict.global.2000	# poly fit
res=slr.global-predict.hind
res_stdev=sd(res[length(res)-50:length(res)]) # stdev for the final 50 years of data
print(res_stdev)
residuals.annual=mat.or.vec(2,nyears.global) #(nr,nc)
residuals.annual[1,]=years.global+2011
residuals.annual[2,]=res
write.table(residuals.annual,
file="./output/residuals.annual.ascii",
row.names=FALSE,
col.names=FALSE
)
white.boot = mat.or.vec(N, nyears.global) # create matrix (nr,nc)
white.boot_sd = rep(NA,N)
for(i in 1:N) {
white.boot[i,1:nyears.global] = sample(res[94:nyears.global],size=nyears.global,replace=TRUE)
white.boot_sd[i] = sd(white.boot[i,])
}
pac <- pacf(res[94:nyears.global], lag.max=5, plot=FALSE)  # apply partial auto-correlation to determine correlation coefficients
print(pac$acf)
res.boot=mat.or.vec(N, nyears.global) #(nr,nc)
for(n in 1:N) {
for(i in 2:nyears.global) {
res.boot[n,i] = pac$acf[1]*res.boot[n,i-1] + rnorm(1,mean=0,sd=white.boot_sd[n])
}
}
slr.boot=mat.or.vec(N, nyears.global) #(nr,nc)
for(i in 1:N) {
slr.boot[i,]=predict.hind+res.boot[i,]
}
plot(years.global+2011,slr.global,type="p",col="green",pch=1,
xlab=("Year"),
ylab=("mean sea-level anomaly (mm) with respect to the year 2000"),
xlim=c(1800,2000),
ylim=c(-400,50))
title("")
# add bootstrap samples
nexamp=3
nrand=sample(N,nexamp)
for(i in 1:nexamp) {
lines(years.global+2011, slr.boot[nrand[i],1:nyears.global], col="red", lwd=1)
}
points(years.global+2011,slr.global,type="p",col="green",pch=1)
lines(years.global+2011,predict.hind,col="black",lty="solid")
legend(x="topleft",
legend=c("Observations (Jevrejava et al (2006)", "polynomial best fit", "best fit + bootstrap residuals"),
col=c("green","black","red"),
lty=c("solid","solid","solid")
)
setwd("~/Documents/Grad/SCRiM/Scripts/Rejection Sampling/clean_version_rls_2011.12.6 2/beta")
source('~/Documents/Grad/SCRiM/Scripts/Rejection Sampling/clean_version_rls_2011.12.6 2/beta/beta.R', echo=TRUE)
slr_test <- array(NA, dim = c(85, length(beta.dist[,1])))
for(i in 1:85){
slr_test[i,] = sea_level_global(beta.dist[,1], beta.dist[,2], beta.dist[,3], beta.dist[,5], beta.dist[,4], i)
}
sea_level_global <- function(a,      # sea level anomaly [m] at t_0
b,      # initial rate      [m/a]
c,      # accelarion        [m/a^2]
c_star, # abrupt increase of rate [m/a]
t_star, # timing of abrupt rate increase
t) {
sea_level_global <- a + b*t + c*(t^2) + c_star * ( (sign(t - t_star) + 1) / 2 ) * (t - t_star)
return(sea_level_global)
}
for(i in 1:85){
slr_test[i,] = sea_level_global(beta.dist[,1], beta.dist[,2], beta.dist[,3], beta.dist[,5], beta.dist[,4], i)
}
matplot(2016:2100, slr_test, type = 'l', lty = 1, col= rgb(0,0,0,0.25))#, xlim = c(2015, (2015+75)))
lines(1:75, (.009*(1:75)), col = "red")
matplot(2016:2100, slr_test, type = 'l', lty = 1, col= rgb(0,0,0,0.25),
ylim = "Sea Level [cm]", xlim = "Years")#, xlim = c(2015, (2015+75)))
matplot(2016:2100, slr_test, type = 'l', lty = 1, col= rgb(0,0,0,0.25),
ylab = "Sea Level [cm]", xlab = "Years")#, xlim = c(2015, (2015+75)))
box(lwd = 1.5)
View(beta.dist)
3*16+12
slr.global
getwd*
getwd()
setwd("~/Documents/Grad/SCRiM/Rejection Sampling/beta")
rm(list = ls(all = TRUE))
set.seed(1) # set the seed to be reproducible
library(timeSeries)
# Define the number of bootstrap/mc samples
N=55000  # Used throughout analysis
# read in the global data from Jevrejava
# see /Users/klaus/Desktop/wip_local/sea-level/data
raw.global<- scan(file="../data/jevrejava_yearly.txt",
what=numeric(), quiet=T)
slr.global.data <- matrix(raw.global, ncol=2, byrow=T)
# fit a simple polynominal model to the data and extract the year 2000 prediion
years.global=slr.global.data[,1]
years.global=years.global-(2011)  # normalize time series to current year 2011
nyears.global=length(years.global)
slr.global=slr.global.data[,2]
# 2nd order polynomial ~ a + bx + cx^2
fit.global=lm(slr.global ~ years.global + I(years.global^2))
# scale the observations such that the slr anomalie is zero in the year 2000
predict.global.2000=predict(fit.global,newdata=data.frame(years.global=-11))
slr.global=slr.global-predict.global.2000		# data
predict.hind=predict(fit.global)-predict.global.2000	# poly fit
### Calculate Residuals during observed time series (data - polynomial fit)  ###
res=slr.global-predict.hind
res_stdev=sd(res[length(res)-50:length(res)]) # stdev for the final 50 years of data
print(res_stdev)
years.global
years.global=slr.global.data[,1]
years.global
length(which(years.global>=1900))
length(which(years.global<1900))
length(which(years.global<=1900))
which(years.global==1900)
years.global=slr.global.data[,1]
years.global=years.global-(2011)  # normalize time series to current year 2011
nyears.global=length(years.global)
slr.global=slr.global.data[,2]
# 2nd order polynomial ~ a + bx + cx^2
fit.global=lm(slr.global ~ years.global + I(years.global^2))
# scale the observations such that the slr anomalie is zero in the year 2000
predict.global.2000=predict(fit.global,newdata=data.frame(years.global=-11))
slr.global=slr.global-predict.global.2000		# data
predict.hind=predict(fit.global)-predict.global.2000	# poly fit
### Calculate Residuals during observed time series (data - polynomial fit)  ###
res=slr.global-predict.hind
res_stdev=sd(res[length(res)-50:length(res)]) # stdev for the final 50 years of data
print(res_stdev)
which(slr.global.data[,1]==1900)
res_stdev=sd(res[length(res)-50:length(res)]) # stdev for the final 50 years of data
print(res_stdev)
# write-out the residuals
residuals.annual=mat.or.vec(2,nyears.global) #(nr,nc)
residuals.annual[1,]=years.global+2011
residuals.annual[2,]=res
white.boot = mat.or.vec(N, nyears.global) # create matrix (nr,nc)
white.boot_sd = rep(NA,N)
for(i in 1:N) {
white.boot[i,1:nyears.global] = sample(res[94:nyears.global],size=nyears.global,replace=TRUE)
white.boot_sd[i] = sd(white.boot[i,])
}
### create new residuals from bootstraps with original AR structure
pac <- pacf(res[94:nyears.global], lag.max=5, plot=FALSE)  # apply partial auto-correlation to determine correlation coefficients
print(pac$acf)
years.global
years.extra=seq(-211,89, length=300) # using jevrejava annual data 1800-2100 (t0=2011)
years.extra
2100-2000
2100-1800
which(slr.global.data[,1]==2000)
slr.global.data[,1][89]
length(seq(-211,89))
test <- seq(1800, 2100)
test
test[89]
which(test==2000)
test-2000
test <- seq(1800, 2100)
test - 2011
test
test - 2011
test <- seq(1879,2100)
test
test - 2015
length(test)
test <- seq(1800, 2100)
test
test - 2011
length(test)
years.extra
years.extra=seq(-211,89, length=301) # using jevrejava annual data 1800-2100 (t0=2011)
years.extra
years.extra=seq(-211,89, length=300) # using jevrejava annual data 1800-2100 (t0=2011)
years.extra
length(seq(-136, 85))
length(seq(-136, 85)) - (2100-2015)
rm(list = ls(all = TRUE))
set.seed(1) # set the seed to be reproducible
library(timeSeries)
# Define the number of bootstrap/mc samples
N=55000  # Used throughout analysis
# read in the global data from Jevrejava
# see /Users/klaus/Desktop/wip_local/sea-level/data
raw.global<- scan(file="../data/jevrejava_yearly.txt",
what=numeric(), quiet=T)
slr.global.data <- matrix(raw.global, ncol=2, byrow=T)
# fit a simple polynominal model to the data and extract the year 2000 prediion
years.global=slr.global.data[,1]
years.global=years.global-(2011)  # normalize time series to current year 2011
nyears.global=length(years.global)
slr.global=slr.global.data[,2]
# 2nd order polynomial ~ a + bx + cx^2
fit.global=lm(slr.global ~ years.global + I(years.global^2))
# scale the observations such that the slr anomalie is zero in the year 2000
predict.global.2000=predict(fit.global,newdata=data.frame(years.global=-11))
slr.global=slr.global-predict.global.2000		# data
predict.hind=predict(fit.global)-predict.global.2000	# poly fit
### Calculate Residuals during observed time series (data - polynomial fit)  ###
res=slr.global-predict.hind
res_stdev=sd(res[length(res)-50:length(res)]) # stdev for the final 50 years of data
print(res_stdev)
# write-out the residuals
residuals.annual=mat.or.vec(2,nyears.global) #(nr,nc)
residuals.annual[1,]=years.global+2011
residuals.annual[2,]=res
write.table(residuals.annual,
file="./output/residuals.annual.ascii",
row.names=FALSE,
col.names=FALSE
)
### Bootstrap the residuals ###
### confine to post-1900 portion of time series ###
white.boot = mat.or.vec(N, nyears.global) # create matrix (nr,nc)
white.boot_sd = rep(NA,N)
for(i in 1:N) {
white.boot[i,1:nyears.global] = sample(res[94:nyears.global],size=nyears.global,replace=TRUE)
white.boot_sd[i] = sd(white.boot[i,])
}
### create new residuals from bootstraps with original AR structure
pac <- pacf(res[94:nyears.global], lag.max=5, plot=FALSE)  # apply partial auto-correlation to determine correlation coefficients
print(pac$acf)
res.boot=mat.or.vec(N, nyears.global) #(nr,nc)
for(n in 1:N) {
for(i in 2:nyears.global) {
res.boot[n,i] = pac$acf[1]*res.boot[n,i-1] + rnorm(1,mean=0,sd=white.boot_sd[n])
}
}
# write out boot strap samples of auto-correlated residuals
#res.boot.t=t(res.boot)
#res.boot.array=mat.or.vec(nyears.global,N+1) #(nr,nc)
# res.boot.array[,1]=years.global+2011
# res.boot.array[,2:1001]=res.boot.t
#write.table(res.boot.array,file="./output/residual_sample.txt",quote=FALSE,row.names=FALSE,col.names=FALSE)
# write out just a simple time-series
#res.boot.simple=mat.or.vec(nyears.global,N) #(nr,nc)
#res.boot.simple[1:N]=res.boot
#write.csv(res.boot.simple,file="./output/just_residuals_sample.csv")
### apply new AUTOCORRELATED residuals to polynomial fit
slr.boot=mat.or.vec(N, nyears.global) #(nr,nc)
for(i in 1:N) {
slr.boot[i,]=predict.hind+res.boot[i,]
}
# define the extrapolation, predict, and center on 2000
years.extra=seq(-211,89, length=300) # using jevrejava annual data 1800-2100 (t0=2011)
n.years.extra=length(years.extra)
predict.global=predict(fit.global,newdata=data.frame(years.global=seq(-211,89,length=300)))-predict.global.2000
### calculate polynomial coefficients for projections ###
boot.fit_coef=mat.or.vec(N, 3)
boot.fit_predict=mat.or.vec(N, n.years.extra)
for(i in 1:N) {
fit.new=lm(slr.boot[i,] ~ years.global + I(years.global^2))
boot.fit_coef[i,1]=fit.new$coefficients[1]
boot.fit_coef[i,2]=fit.new$coefficients[2]
boot.fit_coef[i,3]=fit.new$coefficients[3]
boot.fit_predict[i,]=predict(fit.new,newdata=data.frame(years.global=seq(-211,89,length=300))) -
predict(fit.new,newdata=data.frame(years.global=-11))
}
# define the scenario models
slrmodel <- function(times, slr.normal, c, t.star)
# this function adds the scenarios for unresolved processes using a
# time t.star at which the change happen and an additional sea level
# rate c after t.star
# example call: foo=slrmodel(years.extra,predict.global,1,2050)
{
n.points=length(times)
slr.scenario=slr.normal
for(i in 1:n.points)
{
if (times[i] > t.star)
{
slr.scenario[i]=slr.normal[i]+(times[i]-t.star)*c
}
}
return (slr.scenario)
}
# produce an example scenario projections
scenario.global=slrmodel(years.extra,predict.global,17,4)
# produce many slr scenarios drawing from the prior
###################################################
c.sample=mat.or.vec(N,1) #(nr,nc)
t.star.sample=mat.or.vec(N,1)
scenario.mc=mat.or.vec(N,n.years.extra)
for(n in 1:N)
{
# draw random samples from a uniform distribution
c.sample[n]<-runif(1, min=-15, max=35)
t.star.sample[n]<-runif(1, min=0, max=89)
# produce the scenario
scenario.mc[n,]=slrmodel(years.extra,boot.fit_predict[n,],c.sample[n],t.star.sample[n])
}
scenario.poly.only=scenario.mc   # define the polynomial projections (used as input for pdfs)
### calculate projected residuals ###
res.boot_proj=mat.or.vec(N, n.years.extra) #(nr,nc)
for(n in 1:N) {
for(i in 2:n.years.extra) {
res.boot_proj[n,i] = pac$acf[1]*res.boot_proj[n,i-1]  + rnorm(1,mean=0,sd=white.boot_sd[n])
}
}
### superimpose residuals on polynomial fit projections ###
for(i in 1:N) {
scenario.mc[i,]=scenario.mc[i,]+res.boot_proj[i,]
}
# cut the scenarios within the window
ub.2100=2508
lb.2100=255
# see notes Aug. 16th.
#(pfeffer + thermosteric + reg. uncert.) )
# define arrays for all parameters and slr time series
array=mat.or.vec(N,6)
colnames(array) = c("a","b","c","t.star","c.star","slr")
scenario.filter=mat.or.vec(N,n.years.extra)
for(n in 1:N)
{
if (scenario.poly.only[n,n.years.extra] < ub.2100 && scenario.poly.only[n,n.years.extra] > lb.2100)
{
array[n,1:3]=boot.fit_coef[n,]
array[n,4]=t.star.sample[n] + 2011
array[n,5]=c.sample[n]
array[n,6]=scenario.poly.only[n,n.years.extra]
scenario.filter[n,]=scenario.mc[n,]
}
else
{
array[n,]=NA	# set out of bound entries to missing values
scenario.filter[n,]=NA
}
}
array=removeNA(array)
scenario.filter=removeNA(scenario.filter)  # remove missing values
print(array)
a=lb.2100 # define slr bounds
b=ub.2100
n.bin=50  # number of bins for rejection sampling
s1 = 2    # define shape parameters (yields good fit to expert priors -- pfeffer, sriver, etc.)
s2 = 3
xs <- seq(0, 1, length=n.bin)	# define standard beta function on interval [0,1]
xt <- seq(a, b, length=n.bin)   # transform distribution to slr bounds
beta_pdf<-dbeta(xs, s1, s2)
print(beta_pdf)
### check that pdf integrates to 1 ###
beta_wt_test=beta_pdf*(xs[2]-xs[1])  # standard distribution
print(sum(beta_wt_test))
#beta_wt=beta_pdf*(xt[2]-xt[1])/(b-a) # transformed distribution
beta_wt=beta_pdf/sum(beta_pdf)
print(sum(beta_wt))
# get the uniform pdf
x.sample.CA=seq(0,2500,length=1000)
lb.CA=10
ub.CA=2060
uniform.fit.CA=dunif(x.sample.CA, min=lb.CA, max=ub.CA, log = FALSE)
################################################
### read in model output ###
array = read.table("./output/array_raw.txt")
x.bin=n.bin-1
### read through slr and bin the values accordingly ###
nrows=length(array[,1])
bin.array=array(NA, dim=c(x.bin,nrows,7))
for (i in 1:x.bin)
{
for(n in 1:nrows)
{
if (array[n,7] > xt[i]  && array[n,7] < xt[i+1])
{
bin.array[i,n,1]=array[n,1]
bin.array[i,n,2]=array[n,2]
bin.array[i,n,3]=array[n,3]
bin.array[i,n,4]=array[n,4]
bin.array[i,n,5]=array[n,5]
bin.array[i,n,6]=array[n,6]
bin.array[i,n,7]=array[n,7]
}
}
}
print(bin.array[1,,])
?nrand
rm(list = ls(all = TRUE))
set.seed(1) # set the seed to be reproducible
library(timeSeries)
# Define the number of bootstrap/mc samples
N=55000  # Used throughout analysis
# read in the global data from Jevrejava
# see /Users/klaus/Desktop/wip_local/sea-level/data
raw.global<- scan(file="../data/jevrejava_yearly.txt",
what=numeric(), quiet=T)
slr.global.data <- matrix(raw.global, ncol=2, byrow=T)
# fit a simple polynominal model to the data and extract the year 2000 prediion
years.global=slr.global.data[,1]
years.global=years.global-(2011)  # normalize time series to current year 2011
nyears.global=length(years.global)
slr.global=slr.global.data[,2]
# 2nd order polynomial ~ a + bx + cx^2
fit.global=lm(slr.global ~ years.global + I(years.global^2))
plot(years.global, slr.global, type = 'l')
abline(fit.global)
55000*222
sea_level_global <- function(a,      # sea level anomaly [m] at t_0
b,      # initial rate      [m/a]
c,      # accelarion        [m/a^2]
c_star, # abrupt increase of rate [m/a]
t_star, # timing of abrupt rate increase
t) {
sea_level_global <- a + b*t + c*(t^2) + c_star * ( (sign(t - t_star) + 1) / 2 ) * (t - t_star)
return(sea_level_global)
}
slr_test <- sapply(1:85, function(t) {
sea_level_global(par_reject[,1], par_reject[,2], par_reject[,3], par_reject[,5], par_reject[,4], t[t])
})
for(i in 1:85){
slr_test[i,] = sea_level_global(beta.dist[,1], beta.dist[,2], beta.dist[,3], beta.dist[,5], beta.dist[,4], i)
}
